{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def load_jsonl(file_path, sort_by_id = True):\n",
    "    data = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            json_obj = json.loads(line.strip())\n",
    "            # break\n",
    "            data.append(json_obj)\n",
    "    # print('list has', len(data), 'lines')\n",
    "    if sort_by_id:\n",
    "        return sorted(data, key=lambda x: x['id'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_keys = ['wiki_id_match', 'wiki_par_id_match']\n",
    "reader_keys = ['substring_match', 'exact_match']\n",
    "retriever_file = '/data/tir/projects/tir6/general/afreens/dbqa/retriever_results/evaluations/bm25/nq-dev-kilt.jsonl'\n",
    "reader_file = '/data/tir/projects/tir6/general/afreens/dbqa/reader_results/reader_output_evaluated_with_baselines.jsonl'\n",
    "retriever_text_file = '/data/tir/projects/tir6/general/afreens/dbqa/retriever_results/predictions/bm25/nq-dev-kilt.jsonl'\n",
    "\n",
    "retriever_list = load_jsonl(retriever_file)\n",
    "reader_list = load_jsonl(reader_file)\n",
    "retriever_text_list = load_jsonl(retriever_text_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "def get_pipeline_zeno_results(retriever_list, retriever_text_list, reader_list, k):\n",
    "    compiled_results = []\n",
    "    # retriever_results = []\n",
    "    # reader_results = []\n",
    "\n",
    "    for l_id, (retriever_out, retriever_texts, reader_out) in enumerate(zip(retriever_list, retriever_text_list, reader_list)):\n",
    "        doc_results = {}\n",
    "        doc_results['id'] = retriever_out['id']\n",
    "        doc_results['question'] = retriever_texts['input']\n",
    "        doc_results['output'] = {'context': []}\n",
    "        \n",
    "        # retriever_results_per_doc = []\n",
    "        # reader_results_per_doc = []\n",
    "        if (retriever_out['id']!= reader_out['id']):\n",
    "                print(l_id, 'diff id')\n",
    "        any_wiki_id_match = False\n",
    "        any_wiki_par_id_match = False\n",
    "        for prov_id, (rt_out, rt_text, rd_out) in enumerate(zip(retriever_out['doc-level results'], retriever_texts['output'][0]['provenance'], reader_out['output']['provenance'])):\n",
    "            if (rt_out['wiki_par_id']!= rd_out['docid']):\n",
    "                print(prov_id, 'diff wiki id')\n",
    "            if (rt_text['docid'] != rd_out['docid']):\n",
    "                 print(prov_id, 'diff wiki id')\n",
    "            if prov_id == k:\n",
    "                break\n",
    "            if (prov_id == 0):\n",
    "                 doc_results['output']['answer'] = rd_out['answer']\n",
    "                 doc_results['output']['answer evaluation'] = rd_out['answer_evaluation']\n",
    "            if rt_out['wiki_id_match']:\n",
    "                 any_wiki_id_match = True\n",
    "            if rt_out['wiki_par_id_match']:\n",
    "                 any_wiki_par_id_match = True\n",
    "            context_info = {'wiki_id': rt_out['wiki_id'], 'wiki_par_id': rt_out['wiki_par_id']}\n",
    "            context_info['wiki_id_match'] = rt_out['wiki_id_match']\n",
    "            context_info['wiki_par_id_match'] = rt_out['wiki_par_id_match']\n",
    "            context_info['text'] = rt_text['text']\n",
    "            context_info['score'] = rt_text['score']\n",
    "            doc_results['output']['context'].append(context_info)\n",
    "        \n",
    "        doc_results['output']['summary context evaluation'] = {'wiki_id_match': any_wiki_id_match, \\\n",
    "                                                       'wiki_par_id_match': any_wiki_par_id_match}\n",
    "        reordered_keys = ['answer', 'answer evaluation', 'context', 'summary context evaluation']\n",
    "        doc_results['output'] = {k: doc_results['output'][k] for k in reordered_keys}\n",
    "\n",
    "        compiled_results.append(doc_results)\n",
    "\n",
    "            \n",
    "    return compiled_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_results = get_pipeline_zeno_results(retriever_list, retriever_text_list, reader_list, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/data/tir/projects/tir6/general/afreens/dbqa/compiled_zeno_results/top-1_bm25_llama_nq_dev_kilt_results.json', 'w') as file:\n",
    "    json.dump(compiled_results, file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
